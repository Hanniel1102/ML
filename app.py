from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from PIL import Image
import io
import os
import json
import cv2
from datetime import datetime
import base64

# Thi·∫øt l·∫≠p TensorFlow tr∆∞·ªõc khi import
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # T·∫Øt warning

# Import TensorFlow
try:
    import tensorflow as tf
    # V·ªõi TensorFlow 2.15, s·ª≠ d·ª•ng tf.keras
    from tensorflow import keras
    print(f"‚úÖ TensorFlow version: {tf.__version__}")
except ImportError as e:
    print(f"‚ùå L·ªói import TensorFlow: {e}")
    raise

# Import module ti·ªÅn x·ª≠ l√Ω th√¥ng minh
from image_preprocessing import ImagePreprocessor, preprocess_and_check
# Import image analysis (MODULE CH√çNH cho validation v√† analysis)
from image_analysis import analyze_image
from efficientnet_preprocessor import preprocess_for_efficientnet

app = FastAPI(title="Tomato Disease Detection API")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Bi·∫øn to√†n c·ª•c
model = None
class_names = None
IMG_SIZE = 256
preprocessor = ImagePreprocessor()

# File l∆∞u l·ªãch s·ª≠
HISTORY_FILE = "prediction_history.json"

# Database th√¥ng tin b·ªánh v√† gi·∫£i ph√°p chƒÉm s√≥c
DISEASE_INFO = {
    "Bacterial Spot": {
        "name_vi": "ƒê·ªëm L√° Vi Khu·∫©n",
        "severity": "Cao",
        "description": "B·ªánh do vi khu·∫©n Xanthomonas g√¢y ra, t·∫°o c√°c ƒë·ªëm ƒëen nh·ªè tr√™n l√° v√† qu·∫£, ·∫£nh h∆∞·ªüng nghi√™m tr·ªçng ƒë·∫øn nƒÉng su·∫•t.",
        "symptoms": [
            "ƒê·ªëm nh·ªè m√†u ƒëen ho·∫∑c n√¢u tr√™n l√°, c√≥ vi·ªÅn v√†ng",
            "L√° b·ªã v√†ng v√† r·ª•ng s·ªõm",
            "ƒê·ªëm tr√™n qu·∫£ l√†m gi·∫£m ch·∫•t l∆∞·ª£ng",
            "Lan r·ªông nhanh trong ƒëi·ªÅu ki·ªán ·∫©m ∆∞·ªõt"
        ],
        "causes": [
            "ƒê·ªô ·∫©m cao (>80%)",
            "Nhi·ªát ƒë·ªô 25-30¬∞C",
            "M∆∞a nhi·ªÅu, t∆∞·ªõi n∆∞·ªõc tr·ª±c ti·∫øp l√™n l√°",
            "Vi khu·∫©n l√¢y lan qua v·∫øt th∆∞∆°ng, gi·ªçt n∆∞·ªõc"
        ],
        "treatment": {
            "immediate": [
                "üî¥ C·∫§P B√ÅN: Lo·∫°i b·ªè l√° b·ªánh v√† ti√™u h·ªßy ngay (ƒë·ªët ho·∫∑c ch√¥n s√¢u)",
                "üíß Tr√°nh t∆∞·ªõi n∆∞·ªõc l√™n l√°, ch·ªâ t∆∞·ªõi g·ªëc",
                "üåø Phun thu·ªëc kh√°ng sinh ƒë·ªìng (copper hydroxide) ho·∫∑c streptomycin",
                "üî¨ C√°ch ly c√¢y b·ªánh kh·ªèi c√¢y kh·ªèe m·∫°nh"
            ],
            "shortterm": [
                "Phun thu·ªëc 7-10 ng√†y/l·∫ßn trong 3-4 tu·∫ßn",
                "S·ª≠ d·ª•ng ph√¢n b√≥n gi√†u canxi ƒë·ªÉ tƒÉng c∆∞·ªùng s·ª©c ƒë·ªÅ kh√°ng",
                "C·∫£i thi·ªán tho√°t n∆∞·ªõc, tr√°nh √∫ng n∆∞·ªõc",
                "T·ªâa b·ªõt l√° ƒë·ªÉ tƒÉng th√¥ng gi√≥"
            ],
            "longterm": [
                "Lu√¢n canh c√¢y tr·ªìng (ngh·ªâ 2-3 nƒÉm)",
                "Tr·ªìng gi·ªëng kh√°ng b·ªánh (varieties c√≥ gen kh√°ng)",
                "S·ª≠ d·ª•ng m√†ng ph·ªß ƒë·ªÉ gi·∫£m b·∫Øn n∆∞·ªõc l√™n l√°",
                "Kh·ª≠ tr√πng d·ª•ng c·ª• l√†m v∆∞·ªùn th∆∞·ªùng xuy√™n",
                "X√¢y d·ª±ng h·ªá th·ªëng t∆∞·ªõi nh·ªè gi·ªçt"
            ]
        },
        "prevention": [
            "Ch·ªçn gi·ªëng kh√°ng b·ªánh",
            "T∆∞·ªõi n∆∞·ªõc bu·ªïi s√°ng ƒë·ªÉ l√° kh√¥ nhanh",
            "Kho·∫£ng c√°ch tr·ªìng r·ªông (60-90cm)",
            "Kh·ª≠ tr√πng h·∫°t gi·ªëng tr∆∞·ªõc khi gieo"
        ],
        "products": [
            "Kocide 3000 (copper hydroxide)",
            "Streptomycin sulfate",
            "Mancozeb + copper",
            "Actigard (k√≠ch ho·∫°t mi·ªÖn d·ªãch)"
        ]
    },
    "Early Blight": {
        "name_vi": "B·ªánh H√©o S·ªõm",
        "severity": "Trung b√¨nh - Cao",
        "description": "B·ªánh do n·∫•m Alternaria solani, g√¢y ƒë·ªëm ƒë·ªìng t√¢m tr√™n l√°, th√¢n v√† qu·∫£. Ph·ªï bi·∫øn nh·∫•t ·ªü c√† chua.",
        "symptoms": [
            "ƒê·ªëm tr√≤n c√≥ v√≤ng ƒë·ªìng t√¢m (m·∫Øt b√≤) tr√™n l√° gi√†",
            "L√° v√†ng v√† r·ª•ng t·ª´ d∆∞·ªõi l√™n",
            "V·∫øt th·ªëi ƒëen tr√™n th√¢n g·∫ßn g·ªëc",
            "ƒê·ªëm ƒëen l√µm tr√™n cu·ªëng qu·∫£"
        ],
        "causes": [
            "Nhi·ªát ƒë·ªô ·∫•m (24-29¬∞C)",
            "ƒê·ªô ·∫©m cao, m∆∞a nhi·ªÅu",
            "Dinh d∆∞·ª°ng thi·∫øu h·ª•t (ƒë·∫∑c bi·ªát N, K)",
            "C√¢y gi√†, stress do h·∫°n"
        ],
        "treatment": {
            "immediate": [
                "‚úÇÔ∏è C·∫Øt b·ªè l√° b·ªánh ngay l·∫≠p t·ª©c",
                "üçÑ Phun thu·ªëc di·ªát n·∫•m chlorothalonil ho·∫∑c mancozeb",
                "üå± B√≥n ph√¢n NPK c√¢n ƒë·ªëi, tƒÉng canxi",
                "üí¶ Gi·∫£m t∆∞·ªõi n∆∞·ªõc, tr√°nh ·∫©m ∆∞·ªõt"
            ],
            "shortterm": [
                "Phun thu·ªëc 7 ng√†y/l·∫ßn trong 3-4 tu·∫ßn",
                "Lu√¢n phi√™n c√°c lo·∫°i thu·ªëc di·ªát n·∫•m",
                "B√≥n ph√¢n h·ªØu c∆° tƒÉng c∆∞·ªùng s·ª©c kh·ªèe",
                "D·ªçn s·∫°ch l√° r·ª•ng d∆∞·ªõi g·ªëc"
            ],
            "longterm": [
                "C·∫£i t·∫°o ƒë·∫•t, tƒÉng ch·∫•t h·ªØu c∆°",
                "Tr·ªìng gi·ªëng kh√°ng b·ªánh (Iron Lady, Mountain Magic)",
                "Ph·ªß mulch ƒë·ªÉ tr√°nh b·∫Øn ƒë·∫•t l√™n l√°",
                "T∆∞·ªõi nh·ªè gi·ªçt thay v√¨ t∆∞·ªõi phun",
                "Lu√¢n canh 3-4 nƒÉm"
            ]
        },
        "prevention": [
            "Tr·ªìng xa h·ªç c√† (khoai t√¢y, ·ªõt, c√† t√≠m)",
            "Gi·ªØ kho·∫£ng c√°ch 60-75cm gi·ªØa c√°c c√¢y",
            "B√≥n v√¥i tr∆∞·ªõc khi tr·ªìng (pH 6.0-6.8)",
            "Phun ph√≤ng b·ªánh 2 tu·∫ßn/l·∫ßn"
        ],
        "products": [
            "Daconil (chlorothalonil)",
            "Dithane M-45 (mancozeb)",
            "Azoxystrobin",
            "Copper fungicide"
        ]
    },
    "Healthy": {
        "name_vi": "L√° Kh·ªèe M·∫°nh",
        "severity": "Kh√¥ng c√≥",
        "description": "C√¢y c√† chua ƒëang ph√°t tri·ªÉn t·ªët, kh√¥ng c√≥ d·∫•u hi·ªáu b·ªánh. Ti·∫øp t·ª•c duy tr√¨ chƒÉm s√≥c.",
        "symptoms": [
            "L√° xanh ƒë·ªìng ƒë·ªÅu, kh√¥ng ƒë·ªëm",
            "TƒÉng tr∆∞·ªüng m·∫°nh m·∫Ω",
            "Kh√¥ng c√≥ v·∫øt th·ªëi ho·∫∑c h√©o",
            "Qu·∫£ ph√°t tri·ªÉn b√¨nh th∆∞·ªùng"
        ],
        "causes": [],
        "treatment": {
            "immediate": [
                "‚úÖ Duy tr√¨ ch·∫ø ƒë·ªô chƒÉm s√≥c hi·ªán t·∫°i",
                "üåø Ki·ªÉm tra ƒë·ªãnh k·ª≥ ƒë·ªÉ ph√°t hi·ªán s·ªõm b·ªánh",
                "üíß T∆∞·ªõi n∆∞·ªõc ƒë·ªÅu ƒë·∫∑n, tr√°nh kh√¥ h·∫°n",
                "üåû ƒê·∫£m b·∫£o ƒë·ªß √°nh s√°ng (6-8 gi·ªù/ng√†y)"
            ],
            "shortterm": [
                "B√≥n ph√¢n NPK c√¢n ƒë·ªëi 10-14 ng√†y/l·∫ßn",
                "Theo d√µi s√¢u b·ªánh th∆∞·ªùng xuy√™n",
                "T·ªâa c√†nh ph·ª• (suckers) n·∫øu c·∫ßn",
                "ƒê√≥ng c·ªçc h·ªó tr·ª£ c√¢y khi cao >60cm"
            ],
            "longterm": [
                "X√¢y d·ª±ng l·ªãch tr√¨nh b√≥n ph√¢n khoa h·ªçc",
                "Lu√¢n canh ƒë·ªÉ duy tr√¨ ƒë·ªô ph√¨ ƒë·∫•t",
                "S·ª≠ d·ª•ng ph√¢n compost ƒë·ªãnh k·ª≥",
                "Ghi ch√©p nh·∫≠t k√Ω chƒÉm s√≥c",
                "Phun ph√≤ng b·ªánh sinh h·ªçc"
            ]
        },
        "prevention": [
            "T∆∞·ªõi s√°ng s·ªõm, tr√°nh t·ªëi mu·ªôn",
            "L√†m c·ªè th∆∞·ªùng xuy√™n",
            "B√≥n v√¥i dolomite b·ªï sung Ca, Mg",
            "S·ª≠ d·ª•ng compost ch·∫•t l∆∞·ª£ng cao"
        ],
        "products": [
            "Ph√¢n NPK 16-16-16 (tƒÉng tr∆∞·ªüng)",
            "Ph√¢n NPK 15-5-30 (ra hoa, qu·∫£)",
            "Ph√¢n compost h·ªØu c∆°",
            "Trichoderma (n·∫•m ƒë·ªëi kh√°ng)"
        ]
    },
    "Late Blight": {
        "name_vi": "B·ªánh M·ªëc S∆∞∆°ng",
        "severity": "R·∫•t Cao",
        "description": "B·ªánh nguy hi·ªÉm nh·∫•t, do n·∫•m Phytophthora infestans. C√≥ th·ªÉ ti√™u di·ªát to√†n b·ªô v∆∞·ªùn trong 1-2 tu·∫ßn.",
        "symptoms": [
            "ƒê·ªëm l·ªõn m√†u n√¢u x√°m tr√™n l√°",
            "V·ªát tr·∫Øng m·ªëc ·ªü m·∫∑t d∆∞·ªõi l√° (khi ·∫©m)",
            "Th√¢n ƒëen, ch·∫øt nhanh",
            "Qu·∫£ th·ªëi nhanh, m√πi h√¥i"
        ],
        "causes": [
            "Th·ªùi ti·∫øt m√°t (15-25¬∞C)",
            "ƒê·ªô ·∫©m r·∫•t cao (>90%)",
            "M∆∞a li√™n t·ª•c, s∆∞∆°ng m√π",
            "Gi√≥ lan truy·ªÅn b√†o t·ª≠"
        ],
        "treatment": {
            "immediate": [
                "üö® KH·∫®N C·∫§P: Nh·ªï b·ªè c√¢y b·ªánh n·∫∑ng ngay l·∫≠p t·ª©c!",
                "üî• ƒê·ªët ho·∫∑c ch√¥n s√¢u (kh√¥ng compost)",
                "üíä Phun thu·ªëc di·ªát n·∫•m Metalaxyl + Mancozeb NGAY",
                "üöß C√°ch ly khu v·ª±c b·ªánh, kh√¥ng ƒëi l·∫°i"
            ],
            "shortterm": [
                "Phun thu·ªëc 5-7 ng√†y/l·∫ßn, kh√¥ng b·ªè l·∫ßn n√†o",
                "Lu√¢n phi√™n 2-3 lo·∫°i thu·ªëc ƒë·ªÉ tr√°nh kh√°ng",
                "TƒÉng th√¥ng gi√≥, gi·∫£m ·∫©m t·ªëi ƒëa",
                "Ng·ª´ng t∆∞·ªõi n∆∞·ªõc 3-5 ng√†y n·∫øu c√≥ th·ªÉ",
                "Gi√°m s√°t 24/7, ph√°t hi·ªán s·ªõm"
            ],
            "longterm": [
                "Tr·ªìng gi·ªëng kh√°ng b·ªánh (Matt's Wild Cherry, Defiant PHR)",
                "X√¢y nh√† l∆∞·ªõi/nh√† k√≠nh ƒë·ªÉ ki·ªÉm so√°t ·∫©m",
                "H·ªá th·ªëng t∆∞·ªõi nh·ªè gi·ªçt t·ª± ƒë·ªông",
                "Kh√¥ng tr·ªìng c√† chua li√™n t·ª•c >2 m√πa",
                "Kh·ª≠ tr√πng to√†n b·ªô v∆∞·ªùn sau thu ho·∫°ch"
            ]
        },
        "prevention": [
            "Tr·ªìng gi·ªëng kh√°ng b·ªánh (∆∞u ti√™n s·ªë 1)",
            "Che m∆∞a b·∫±ng m√°i che ho·∫∑c mulch plastic",
            "Phun ph√≤ng tr∆∞·ªõc m∆∞a 1-2 ng√†y",
            "Kho·∫£ng c√°ch >90cm, kh√¥ng tr·ªìng d√†y"
        ],
        "products": [
            "Ridomil Gold (Metalaxyl + Mancozeb) - ∆ØU TI√äN",
            "Revus (Mandipropamid)",
            "Curzate (Cymoxanil)",
            "Ranman (Cyazofamid)"
        ]
    },
    "Septoria Leaf Spot": {
        "name_vi": "ƒê·ªëm L√° Septoria",
        "severity": "Trung b√¨nh",
        "description": "B·ªánh do n·∫•m Septoria lycopersici, g√¢y ƒë·ªëm nh·ªè c√≥ ch·∫•m ƒëen gi·ªØa, th∆∞·ªùng ·ªü l√° gi√†.",
        "symptoms": [
            "ƒê·ªëm tr√≤n nh·ªè (2-3mm) m√†u x√°m/n√¢u",
            "Ch·∫•m ƒëen nh·ªè ·ªü gi·ªØa ƒë·ªëm (b√†o t·ª≠ n·∫•m)",
            "Vi·ªÅn v√†ng quanh ƒë·ªëm",
            "L√° v√†ng v√† r·ª•ng t·ª´ d∆∞·ªõi l√™n"
        ],
        "causes": [
            "Nhi·ªát ƒë·ªô ·∫•m (20-25¬∞C)",
            "ƒê·ªô ·∫©m cao, m∆∞a ph√πn",
            "L√° b·ªã n∆∞·ªõc b·∫Øn t·ª´ ƒë·∫•t",
            "C√¢y tr·ªìng qu√° d√†y"
        ],
        "treatment": {
            "immediate": [
                "‚úÇÔ∏è C·∫Øt b·ªè l√° b·ªánh (ƒë·∫∑c bi·ªát l√° d∆∞·ªõi g·ªëc)",
                "üçÑ Phun thu·ªëc di·ªát n·∫•m chlorothalonil",
                "üåæ Ph·ªß r∆°m r·∫° d∆∞·ªõi g·ªëc, tr√°nh b·∫Øn ƒë·∫•t",
                "üí® T·ªâa l√° tƒÉng th√¥ng gi√≥"
            ],
            "shortterm": [
                "Phun thu·ªëc 10-14 ng√†y/l·∫ßn",
                "T∆∞·ªõi s√°ng s·ªõm, tr√°nh t·ªëi",
                "B√≥n ph√¢n c√¢n ƒë·ªëi NPK + micronutrients",
                "D·ªçn s·∫°ch l√° r·ª•ng h√†ng tu·∫ßn"
            ],
            "longterm": [
                "Ph·ªß mulch plastic ƒëen ƒë·ªÉ tr√°nh b·∫Øn ƒë·∫•t",
                "Tr·ªìng gi·ªëng kh√°ng b·ªánh (Legend, Plum Regal)",
                "Lu√¢n canh 2-3 nƒÉm",
                "Gi√†n leo cao, tr√°nh l√° ch·∫°m ƒë·∫•t",
                "H·ªá th·ªëng t∆∞·ªõi nh·ªè gi·ªçt"
            ]
        },
        "prevention": [
            "Kho·∫£ng c√°ch tr·ªìng 60-75cm",
            "T·ªâa l√° d∆∞·ªõi g·ªëc cao 30cm",
            "Phun ph√≤ng tr∆∞·ªõc m√πa m∆∞a",
            "Kh√¥ng t∆∞·ªõi phun, ch·ªâ t∆∞·ªõi g·ªëc"
        ],
        "products": [
            "Bravo (chlorothalonil)",
            "Mancozeb",
            "Copper fungicide",
            "Azoxystrobin"
        ]
    },
    "Yellow Leaf Curl Virus": {
        "name_vi": "Virus Cu·ªôn L√° V√†ng",
        "severity": "R·∫•t Cao",
        "description": "B·ªánh virus do ru·ªìi tr·∫Øng (whitefly) truy·ªÅn. KH√îNG C√ì THU·ªêC CH·ªÆA, ch·ªâ ki·ªÉm so√°t ru·ªìi tr·∫Øng.",
        "symptoms": [
            "L√° cu·ªôn l·∫°i, v√†ng √∫a",
            "C√¢y c√≤i c·ªçc, kh√¥ng l·ªõn",
            "Hoa r·ª•ng, kh√¥ng ƒë·∫≠u qu·∫£",
            "Ru·ªìi tr·∫Øng bay r·∫•t nhi·ªÅu khi lay c√¢y"
        ],
        "causes": [
            "Ru·ªìi tr·∫Øng (Bemisia tabaci) truy·ªÅn virus",
            "Th·ªùi ti·∫øt n√≥ng kh√¥ (>30¬∞C)",
            "C√¢y tr·ªìng li√™n t·ª•c, kh√¥ng lu√¢n canh",
            "Kh√¥ng c√≥ l∆∞·ªõi ch·∫Øn c√¥n tr√πng"
        ],
        "treatment": {
            "immediate": [
                "üî¥ KH√îNG C√ì THU·ªêC CH·ªÆA - Nh·ªï b·ªè c√¢y b·ªánh NGAY!",
                "ü™∞ Di·ªát ru·ªìi tr·∫Øng kh·∫©n c·∫•p: Imidacloprid ho·∫∑c Thiamethoxam",
                "üü® Treo b·∫´y d√≠nh m√†u v√†ng (yellow sticky traps)",
                "üßº X·ªãt x√† ph√≤ng g·ªëc d·∫ßu neem ƒë·ªÉ ƒëu·ªïi ru·ªìi"
            ],
            "shortterm": [
                "Phun thu·ªëc di·ªát ru·ªìi tr·∫Øng 5 ng√†y/l·∫ßn trong 3 tu·∫ßn",
                "Treo b·∫´y v√†ng m·ªói 5-10m",
                "X·ªãt n∆∞·ªõc m·∫°nh d∆∞·ªõi l√° ƒë·ªÉ ƒë√°nh r∆°i ru·ªìi",
                "Che l∆∞·ªõi ch·∫Øn c√¥n tr√πng (mesh 50)",
                "Lo·∫°i b·ªè c·ªè d·∫°i (·ªï ch·ª©a ru·ªìi tr·∫Øng)"
            ],
            "longterm": [
                "Tr·ªìng gi·ªëng kh√°ng virus (Tygress, SV7203)",
                "Nh√† l∆∞·ªõi/nh√† k√≠nh v·ªõi l∆∞·ªõi ch·∫Øn",
                "Kh√¥ng tr·ªìng c√† chua g·∫ßn d∆∞a, b√≠",
                "Lu√¢n canh 6 th√°ng, ngh·ªâ ƒë·∫•t",
                "S·ª≠ d·ª•ng ph·∫£n quang b·∫°c (silver mulch) ƒëu·ªïi ru·ªìi",
                "Tr·ªìng c√¢y b·∫´y (h∆∞·ªõng d∆∞∆°ng) xung quanh"
            ]
        },
        "prevention": [
            "L∆∞·ªõi ch·∫Øn 40-50 mesh t·ª´ khi gieo h·∫°t",
            "Gi√°m s√°t ru·ªìi tr·∫Øng h√†ng tu·∫ßn",
            "Phun d·∫ßu neem ph√≤ng b·ªánh",
            "Tr·ªìng gi·ªëng kh√°ng virus",
            "Tr√°nh mua c√¢y gi·ªëng c√≥ ru·ªìi tr·∫Øng"
        ],
        "products": [
            "Imidacloprid (Confidor, Admire)",
            "Thiamethoxam (Actara)",
            "Spiromesifen (Oberon) - di·ªát tr·ª©ng/nh·ªông",
            "D·∫ßu Neem h·ªØu c∆°",
            "B·∫´y d√≠nh v√†ng (Yellow sticky traps)"
        ]
    }
}

def get_disease_recommendation(disease_name: str, confidence: float) -> dict:
    """
    L·∫•y th√¥ng tin khuy·∫øn ngh·ªã v√† gi·∫£i ph√°p cho b·ªánh
    
    Args:
        disease_name: T√™n b·ªánh (ti·∫øng Anh)
        confidence: ƒê·ªô tin c·∫≠y (%)
        
    Returns:
        Dictionary ch·ª©a ƒë·∫ßy ƒë·ªß th√¥ng tin b·ªánh v√† gi·∫£i ph√°p
    """
    if disease_name not in DISEASE_INFO:
        return {
            "name_vi": disease_name,
            "severity": "Kh√¥ng x√°c ƒë·ªãnh",
            "description": "Kh√¥ng c√≥ th√¥ng tin chi ti·∫øt",
            "recommendations": []
        }
    
    info = DISEASE_INFO[disease_name]
    
    # T·∫°o khuy·∫øn ngh·ªã d·ª±a tr√™n ƒë·ªô tin c·∫≠y
    recommendations = []
    
    if confidence >= 90:
        certainty = "R·∫§T CAO"
        action_level = "√Åp d·ª•ng ngay t·∫•t c·∫£ bi·ªán ph√°p ƒëi·ªÅu tr·ªã"
    elif confidence >= 75:
        certainty = "CAO"
        action_level = "√Åp d·ª•ng bi·ªán ph√°p ƒëi·ªÅu tr·ªã khuy·∫øn ngh·ªã"
    elif confidence >= 60:
        certainty = "TRUNG B√åNH"
        action_level = "Theo d√µi th√™m v√† √°p d·ª•ng bi·ªán ph√°p ph√≤ng ng·ª´a"
    else:
        certainty = "TH·∫§P"
        action_level = "C·∫ßn ch·ª•p ·∫£nh r√µ h∆°n ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c"
    
    return {
        "name_vi": info["name_vi"],
        "severity": info["severity"],
        "certainty": certainty,
        "confidence": confidence,
        "description": info["description"],
        "symptoms": info["symptoms"],
        "causes": info["causes"],
        "treatment": info["treatment"],
        "prevention": info["prevention"],
        "products": info["products"],
        "action_level": action_level
    }

# Load l·ªãch s·ª≠ t·ª´ file
def load_history():
    """Load l·ªãch s·ª≠ d·ª± ƒëo√°n t·ª´ file"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

# L∆∞u l·ªãch s·ª≠ v√†o file
def save_history(history):
    """L∆∞u l·ªãch s·ª≠ d·ª± ƒëo√°n v√†o file"""
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói l∆∞u l·ªãch s·ª≠: {e}")

# Th√™m k·∫øt qu·∫£ v√†o l·ªãch s·ª≠
def add_to_history(result_data):
    """Th√™m k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o l·ªãch s·ª≠"""
    history = load_history()
    
    # Gi·ªõi h·∫°n 100 k·∫øt qu·∫£ g·∫ßn nh·∫•t
    if len(history) >= 100:
        history = history[-99:]
    
    history.append(result_data)
    save_history(history)
    return len(history)

# Load model khi kh·ªüi ƒë·ªông
@app.on_event("startup")
async def load_model_startup():
    global model, class_names, IMG_SIZE
    
    print("üöÄ ƒêang kh·ªüi ƒë·ªông server...")
    
    # T√¨m v√† load model (ch·ªâ file .h5)
    model_paths = [
        "best_tomato_model.h5",  # Model .h5 m·ªõi nh·∫•t
        "Tomato_EfficientNetB0_Final.h5",  # Model .h5 backup
        "models/best_model.h5",
        "model.h5"
    ]
    
    # Define custom layers cho model t·ªëi ∆∞u
    @tf.keras.utils.register_keras_serializable()
    class SpatialAttention(tf.keras.layers.Layer):
        """Spatial Attention mechanism"""
        def __init__(self, kernel_size=7, **kwargs):
            super().__init__(**kwargs)
            self.kernel_size = kernel_size
            
        def build(self, input_shape):
            self.conv = tf.keras.layers.Conv2D(
                filters=1,
                kernel_size=self.kernel_size,
                padding='same',
                activation='sigmoid',
                use_bias=False
            )
            super().build(input_shape)
            
        def call(self, inputs):
            avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
            max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
            concat = tf.concat([avg_pool, max_pool], axis=-1)
            attention = self.conv(concat)
            return inputs * attention
        
        def get_config(self):
            config = super().get_config()
            config.update({"kernel_size": self.kernel_size})
            return config
    
    @tf.keras.utils.register_keras_serializable()
    class MixUp(tf.keras.layers.Layer):
        """MixUp augmentation layer"""
        def __init__(self, alpha=0.2, **kwargs):
            super().__init__(**kwargs)
            self.alpha = alpha
        
        def get_config(self):
            config = super().get_config()
            config.update({"alpha": self.alpha})
            return config
    
    custom_objects = {
        'SpatialAttention': SpatialAttention,
        'MixUp': MixUp
    }
    
    loaded_model = None
    for model_path in model_paths:
        if os.path.exists(model_path):
            try:
                print(f"üîÑ ƒêang load model t·ª´: {model_path}")
                
                # Load model .h5 v·ªõi custom objects
                try:
                    loaded_model = keras.models.load_model(
                        model_path, 
                        custom_objects=custom_objects,
                        compile=False
                    )
                    print(f"‚úÖ ƒê√£ load model .h5 th√†nh c√¥ng")
                except Exception as load_error:
                    # Fallback: d√πng tf.keras
                    print(f"‚ö†Ô∏è Th·ª≠ fallback v·ªõi tf.keras...")
                    loaded_model = tf.keras.models.load_model(
                        model_path, 
                        custom_objects=custom_objects,
                        compile=False
                    )
                
                model = loaded_model
                print(f"‚úÖ ƒê√£ load model: {model_path}")
                print(f"üìä Model info: input_shape={model.input_shape}, output_shape={model.output_shape}")
                
                # Compile l·∫°i model
                model.compile(
                    optimizer='adam',
                    loss='categorical_crossentropy',
                    metrics=['accuracy']
                )
                print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c compile l·∫°i")
                break
            except Exception as e:
                import traceback
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load model {model_path}:")
                print(f"   {str(e)[:300]}")
                traceback.print_exc()
                continue
    
    if model is None:
        print("‚ùå Kh√¥ng t√¨m th·∫•y model n√†o c√≥ th·ªÉ load ƒë∆∞·ª£c!")
        print("üí° Vui l√≤ng ki·ªÉm tra l·∫°i file model ho·∫∑c train l·∫°i model v·ªõi TensorFlow 2.15.0")
        raise RuntimeError("Model not found!")
    
    # Load class names - ∆Øu ti√™n t·ª´ file JSON, sau ƒë√≥ t·ª´ Train dataset
    class_names = None
    
    # C√°ch 1: Load t·ª´ file JSON (ƒë√£ ƒë∆∞·ª£c l∆∞u khi training)
    if os.path.exists('models/class_names.json'):
        with open('models/class_names.json', 'r', encoding='utf-8') as f:
            class_names = json.load(f)
        print(f"‚úÖ ƒê√£ load class names t·ª´ file JSON: {class_names}")
    
    # C√°ch 2: Load t·ª´ Train dataset directory (th·ª© t·ª± alphabet)
    if class_names is None:
        train_dirs = [
            "Tomato/Train",
            "../Hocmaynangcao/Tomato/Train",
            "H:/nam4ki1/Hocmaynangcao/Tomato/Train"
        ]
        
        for train_dir in train_dirs:
            if os.path.exists(train_dir):
                # L·∫•y t√™n folder v√† sort theo alphabet (gi·ªëng TensorFlow)
                class_folders = sorted([d for d in os.listdir(train_dir) 
                                       if os.path.isdir(os.path.join(train_dir, d))])
                if class_folders:
                    class_names = class_folders
                    print(f"‚úÖ ƒê√£ load class names t·ª´ Train dataset: {class_names}")
                    print(f"üìÇ Train directory: {train_dir}")
                    break
    
    # C√°ch 3: Fallback - hardcode n·∫øu kh√¥ng t√¨m th·∫•y
    if class_names is None:
        class_names = [
            "Bacterial Spot",
            "Early Blight", 
            "Healthy",
            "Late Blight",
            "Septoria Leaf Spot",
            "Yellow Leaf Curl Virus"
        ]
        print(f"‚ö†Ô∏è Class names FALLBACK (hardcoded): {class_names}")
    
    IMG_SIZE = model.input_shape[1]
    print(f"üìè Image size: {IMG_SIZE}x{IMG_SIZE}")
    print(f"üìù S·ªë l∆∞·ª£ng classes: {len(class_names)}")
    print(f"‚úÖ Server ƒë√£ s·∫µn s√†ng!\n")

# API endpoint ch√≠nh
@app.get("/", response_class=HTMLResponse)
async def read_root():
    with open("templates/index.html", "r", encoding="utf-8") as f:
        return f.read()

@app.get("/favicon.ico")
async def favicon():
    """Tr·∫£ v·ªÅ empty response ƒë·ªÉ tr√°nh l·ªói 404"""
    from fastapi.responses import Response
    return Response(status_code=204)

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """API d·ª± ƒëo√°n b·ªánh t·ª´ ·∫£nh upload - v·ªõi ki·ªÉm tra th√¥ng minh"""
    global model, class_names, IMG_SIZE
    
    if model is None:
        raise HTTPException(status_code=503, detail="Model ch∆∞a ƒë∆∞·ª£c load")
    
    try:
        # ƒê·ªçc ·∫£nh
        contents = await file.read()
        img = Image.open(io.BytesIO(contents))
        
        # Chuy·ªÉn sang RGB n·∫øu c·∫ßn
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # === B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù ·∫¢NH GI·ªêNG TRAINING ===
        # Model train v·ªõi preprocessing ƒë∆°n gi·∫£n: resize + rescale (1./255)
        # KH√îNG D√ôNG CLAHE/SHARPEN v√¨ training kh√¥ng d√πng!
        print("\n[Simple Preprocessing] Resize + Rescale only (matching training)")
        
        # L∆∞u ·∫£nh g·ªëc ƒë·ªÉ hi·ªÉn th·ªã
        buffered_original = io.BytesIO()
        img.save(buffered_original, format="JPEG", quality=95)
        original_base64 = base64.b64encode(buffered_original.getvalue()).decode()
        
        # Resize ·∫£nh
        img_resized = img.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.BICUBIC)
        preprocessed_img = img_resized
        
        # L∆∞u ·∫£nh ƒë√£ resize
        buffered_resized = io.BytesIO()
        img_resized.save(buffered_resized, format="JPEG", quality=95)
        resized_base64 = base64.b64encode(buffered_resized.getvalue()).decode()
        
        # Convert PIL Image sang bytes ƒë·ªÉ ph√¢n t√≠ch
        buffered_temp = io.BytesIO()
        preprocessed_img.save(buffered_temp, format="JPEG", quality=95)
        preprocessed_contents = buffered_temp.getvalue()
        
        # === B∆Ø·ªöC 2: PH√ÇN T√çCH ·∫¢NH ƒê√É X·ª¨ L√ù - S·ª¨ D·ª§NG image_analysis.py ===
        # Ph√¢n t√≠ch ·∫£nh ƒê√É ƒë∆∞·ª£c l√†m s·∫°ch: shape, color, texture
        print("\n[Image Analysis] Analyzing preprocessed image...")
        analysis_result = analyze_image(preprocessed_contents)
        
        # Ki·ªÉm tra xem c√≥ ph·∫£i ·∫£nh l√° kh√¥ng
        final_score = analysis_result['finalScore']
        is_leaf = analysis_result['isLeaf']
        
        if not is_leaf:
            # L·∫•y ƒë·∫ßy ƒë·ªß th√¥ng tin ƒë·ªÉ debug
            shape_data = analysis_result['shape']
            color_data = analysis_result['color']
            texture_data = analysis_result['texture']
            
            # Tr√≠ch xu·∫•t c√°c metrics quan tr·ªçng
            detailed_metrics = {
                "overall_score": round(final_score['score'] * 100, 1),
                "confidence_level": final_score['confidence'],
                
                # Shape metrics
                "shape": {
                    "score": final_score['shapeScore'],
                    "aspectRatio": shape_data.get('aspectRatio', 'N/A'),
                    "mainObjectRatio": shape_data.get('mainObjectRatio', 'N/A'),
                    "greenDensity": shape_data.get('greenDensity', 'N/A'),
                    "roundness": shape_data.get('roundness', 'N/A'),
                    "elongation": shape_data.get('elongation', 'N/A')
                },
                
                # Color metrics
                "color": {
                    "score": final_score['colorScore'],
                    "greenRatio": color_data.get('greenRatio', 'N/A'),
                    "yellowRatio": color_data.get('yellowRatio', 'N/A'),
                    "brownRatio": color_data.get('brownRatio', 'N/A'),
                    "avgSaturation": color_data.get('avgSaturation', 'N/A'),
                    "avgHue": color_data.get('avgHue', 'N/A')
                },
                
                # Texture/Vein metrics
                "texture": {
                    "score": final_score['textureScore'],
                    "veinScore": texture_data.get('veinScore', 'N/A'),
                    "edgeDensity": texture_data.get('edgeDensity', 'N/A'),
                    "contrast": texture_data.get('contrast', 'N/A')
                },
                
                # Th√¥ng tin tr·ªçng s·ªë (n·∫øu c√≥ dynamic weighting)
                "weights_used": final_score.get('weights_used', {
                    "shape": 0.35,
                    "color": 0.50,
                    "texture": 0.15
                }),
                "situation": final_score.get('situation', 'normal')
            }
            
            # T·∫°o th√¥ng b√°o chi ti·∫øt
            criteria_check = {
                "green_ratio_check": {
                    "value": color_data.get('greenRatio', '0'),
                    "threshold": "‚â• 0.20 (20%)",
                    "passed": float(color_data.get('greenRatio', 0)) >= 0.20
                },
                "vein_score_check": {
                    "value": texture_data.get('veinScore', '0'),
                    "threshold": "‚â• 0.05",
                    "passed": float(texture_data.get('veinScore', 0)) >= 0.05
                },
                "green_density_check": {
                    "value": shape_data.get('greenDensity', '0'),
                    "threshold": "‚â• 0.15 (15%)",
                    "passed": float(shape_data.get('greenDensity', 0)) >= 0.15
                },
                "overall_score_check": {
                    "value": f"{final_score['score'] * 100:.1f}%",
                    "threshold": "‚â• 60%",
                    "passed": final_score['score'] >= 0.60
                }
            }
            
            return JSONResponse({
                "success": False,
                "error": "NOT_LEAF_IMAGE",
                "message": f"‚ö†Ô∏è {final_score['recommendation']}",
                "reason": final_score['confidence'],
                "recommendation": "Vui l√≤ng upload ·∫£nh l√° c√† chua r√µ r√†ng ƒë·ªÉ ph√°t hi·ªán b·ªánh",
                
                # Th√¥ng tin chi ti·∫øt
                "detailed_analysis": detailed_metrics,
                "criteria_check": criteria_check,
                
                # Backward compatibility
                "confidence": round(final_score['score'] * 100, 1),
                "analysis": {
                    "score": round(final_score['score'] * 100, 1),
                    "shapeScore": final_score['shapeScore'],
                    "colorScore": final_score['colorScore'],
                    "textureScore": final_score['textureScore'],
                    "greenRatio": analysis_result['color']['greenRatio'],
                    "veinScore": analysis_result['texture']['veinScore']
                }
            })
        
        # === B∆Ø·ªöC 3: CHU·∫®N B·ªä ·∫¢NH CHO MODEL ===
        # QUAN TR·ªåNG: Model ƒë∆∞·ª£c train v·ªõi input [0, 255] (KH√îNG rescale tr∆∞·ªõc khi v√†o model)
        # Model c√≥ data_augmentation layer b√™n trong, n√≥ s·∫Ω t·ª± x·ª≠ l√Ω
        # Ch·ªâ c·∫ßn resize v·ªÅ ƒë√∫ng k√≠ch th∆∞·ªõc v√† gi·ªØ nguy√™n range [0, 255]
        enhanced_img = preprocessed_img
        img_array = np.array(preprocessed_img, dtype=np.float32)  # Gi·ªØ nguy√™n [0, 255]
        img_array = np.expand_dims(img_array, axis=0)
        
        print(f"[Model Input] ‚úÖ Array shape: {img_array.shape}, range: [{img_array.min():.1f}, {img_array.max():.1f}] (RAW [0-255])")
        
        # === B∆Ø·ªöC 4: D·ª∞ ƒêO√ÅN B·ªÜNH ===
        predictions = model.predict(img_array, verbose=0)
        predicted_class_idx = int(np.argmax(predictions[0]))
        confidence = float(predictions[0][predicted_class_idx] * 100)
        
        # DEBUG: In ra prediction values
        print(f"\n[DEBUG Prediction] All class probabilities:")
        for i, class_name in enumerate(class_names):
            print(f"  {i}. {class_name}: {predictions[0][i]*100:.2f}%")
        print(f"[DEBUG Prediction] Predicted: {class_names[predicted_class_idx]} ({confidence:.2f}%)\n")
        
        # Top 5 predictions
        num_top = min(5, len(class_names))
        top_idx = np.argsort(predictions[0])[-num_top:][::-1]
        top_predictions = [
            {
                "class": class_names[int(idx)],
                "confidence": float(predictions[0][idx] * 100)
            }
            for idx in top_idx
        ]
        
        # === B∆Ø·ªöC 5: PH√ÇN T√çCH CH·∫§T L∆Ø·ª¢NG ·∫¢NH (t·ª´ analysis_result) ===
        image_analysis_data = {
            "score": round(final_score['score'] * 100, 1),
            "confidence": final_score['confidence'],
            "shapeScore": final_score['shapeScore'],
            "colorScore": final_score['colorScore'],
            "textureScore": final_score['textureScore'],
            "greenRatio": analysis_result['color']['greenRatio'],
            "veinScore": analysis_result['texture']['veinScore'],
            "edgeDensity": analysis_result['texture']['edgeDensity'],
            "recommendation": final_score['recommendation'],
            # Th√™m metrics t·ª´ analysis_result
            "brightness": analysis_result.get('metrics', {}).get('brightness', 128),
            "contrast": analysis_result.get('metrics', {}).get('contrast', 50),
            "sharpness": analysis_result.get('metrics', {}).get('sharpness', 50),
            "noise": analysis_result.get('metrics', {}).get('noise', 1000)
        }
        
        # === B∆Ø·ªöC 6: L∆ØU V√ÄO L·ªäCH S·ª¨ ===
        # Convert ·∫£nh sang base64 ƒë·ªÉ l∆∞u thumbnail
        img_thumbnail = img.copy()
        img_thumbnail.thumbnail((150, 150))
        buffered = io.BytesIO()
        img_thumbnail.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        # === B∆Ø·ªöC 7: L·∫§Y TH√îNG TIN B·ªÜNH V√Ä KHUY·∫æN NGH·ªä ===
        disease_recommendation = get_disease_recommendation(
            class_names[predicted_class_idx], 
            confidence
        )
        
        history_entry = {
            "id": len(load_history()) + 1,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "filename": file.filename,
            "predicted_class": class_names[predicted_class_idx],
            "confidence": round(confidence, 2),
            "vein_score": analysis_result['texture']['veinScore'],
            "thumbnail": f"data:image/jpeg;base64,{img_base64}",
            "top_predictions": top_predictions,
            "image_analysis": image_analysis_data,
            "disease_info": disease_recommendation,
            "preprocessing_summary": {"method": "simple", "steps": ["resize", "rescale"]}
        }
        add_to_history(history_entry)
        
        # Lo·∫°i b·ªè numpy arrays v√† convert numpy types sang Python types
        def clean_value(val):
            """Convert numpy types to Python native types"""
            if isinstance(val, np.ndarray):
                return val.tolist()
            elif isinstance(val, (np.integer, np.int64, np.int32)):
                return int(val)
            elif isinstance(val, (np.floating, np.float64, np.float32)):
                return float(val)
            elif isinstance(val, (np.bool_, bool)):
                return bool(val)
            elif isinstance(val, dict):
                return {k: clean_value(v) for k, v in val.items()}
            elif isinstance(val, list):
                return [clean_value(v) for v in val]
            else:
                return val
        
        # T·∫°o visualization preprocessing steps (6 b∆∞·ªõc ƒë·∫ßy ƒë·ªß)
        # G·ªçi preprocess_for_efficientnet ƒë·ªÉ l·∫•y steps visualization
        print("\n[Preprocessing Visualization] Generating 6-step visualization...")
        from efficientnet_preprocessor import preprocess_for_efficientnet
        preprocessing_result = preprocess_for_efficientnet(img, target_size=(IMG_SIZE, IMG_SIZE))
        
        preprocessing_steps_clean = []
        if preprocessing_result and 'steps' in preprocessing_result:
            for step in preprocessing_result['steps']:
                preprocessing_steps_clean.append({
                    'name': step.get('name', 'Unknown'),
                    'description': step.get('description', ''),
                    'image_base64': step.get('image_base64', None),
                    'metrics': clean_value(step.get('metrics', {}))
                })
        
        # N·∫øu kh√¥ng c√≥ steps, d√πng fallback 2 steps
        if not preprocessing_steps_clean:
            preprocessing_steps_clean = [
                {
                    'name': 'resize',
                    'description': f'Resized to {IMG_SIZE}x{IMG_SIZE}',
                    'image_base64': f"data:image/jpeg;base64,{resized_base64}",
                    'metrics': {}
                },
                {
                    'name': 'normalize',
                    'description': 'Rescaled to [0,1] range',
                    'image_base64': f"data:image/jpeg;base64,{resized_base64}",
                    'metrics': {}
                }
            ]
        
        # T·∫°o summary v√† clean numpy types
        preprocessing_summary = preprocessing_result.get('summary', {}) if preprocessing_result else {}
        if not preprocessing_summary:
            preprocessing_summary = {
                "total_steps": len(preprocessing_steps_clean),
                "actions_taken": [step['name'] for step in preprocessing_steps_clean],
                "final_quality": {
                    "brightness": "T·ªët",
                    "contrast": "T·ªët",
                    "noise": "S·∫°ch",
                    "sharpness": "S·∫Øc n√©t"
                }
            }
        else:
            # Clean numpy types trong summary
            preprocessing_summary = clean_value(preprocessing_summary)
        
        response_data = {
            "success": True,
            "predicted_class": class_names[predicted_class_idx],
            "confidence": confidence,
            "top_predictions": top_predictions,
            "image_analysis": image_analysis_data,
            "preprocessing": {
                "steps": preprocessing_steps_clean,
                "summary": preprocessing_summary
            },
            "processedImages": {
                "original": f"data:image/jpeg;base64,{original_base64}",
                "resized": f"data:image/jpeg;base64,{resized_base64}"
            },
            "history_id": history_entry["id"],
            "disease_info": disease_recommendation  # Th√¥ng tin chi ti·∫øt v·ªÅ b·ªánh
        }
        
        return JSONResponse(response_data)
        
    except Exception as e:
        import traceback
        traceback.print_exc()  # In ra console ƒë·ªÉ debug
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}")

@app.get("/history")
async def get_history():
    """L·∫•y l·ªãch s·ª≠ d·ª± ƒëo√°n"""
    try:
        history = load_history()
        # S·∫Øp x·∫øp theo th·ªùi gian m·ªõi nh·∫•t
        history.reverse()
        return JSONResponse({
            "success": True,
            "count": len(history),
            "history": history
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.get("/history/{item_id}")
async def get_history_item(item_id: int):
    """L·∫•y chi ti·∫øt m·ªôt item trong l·ªãch s·ª≠"""
    try:
        history = load_history()
        item = next((h for h in history if h.get('id') == item_id), None)
        
        if item is None:
            return JSONResponse({
                "success": False,
                "error": "Kh√¥ng t√¨m th·∫•y item"
            }, status_code=404)
        
        return JSONResponse({
            "success": True,
            "item": item
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.delete("/history/{item_id}")
async def delete_history_item(item_id: int):
    """X√≥a m·ªôt item trong l·ªãch s·ª≠"""
    try:
        history = load_history()
        history = [h for h in history if h.get('id') != item_id]
        save_history(history)
        return JSONResponse({
            "success": True,
            "message": "ƒê√£ x√≥a th√†nh c√¥ng"
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.delete("/history")
async def clear_history():
    """X√≥a to√†n b·ªô l·ªãch s·ª≠"""
    try:
        save_history([])
        return JSONResponse({
            "success": True,
            "message": "ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠"
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.post("/analyze")
async def analyze_image_endpoint(file: UploadFile = File(...)):
    """
    Ph√¢n t√≠ch ·∫£nh chi ti·∫øt: shape, color, texture
    Preprocessing TR∆Ø·ªöC khi ph√¢n t√≠ch ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c h∆°n
    """
    try:
        # ƒê·ªçc file
        contents = await file.read()
        img = Image.open(io.BytesIO(contents))
        
        # Chuy·ªÉn sang RGB n·∫øu c·∫ßn
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Ph√¢n t√≠ch ·∫£nh G·ªêC (kh√¥ng preprocess)
        print("\n[Analyze Endpoint] Analyzing original image...")
        result = analyze_image(contents)
        
        return JSONResponse({
            "success": True,
            "analysis": result
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "L·ªói khi ph√¢n t√≠ch ·∫£nh"
        }, status_code=500)

@app.get("/health")
async def health_check():
    """Ki·ªÉm tra tr·∫°ng th√°i server"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "num_classes": len(class_names) if class_names else 0
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
