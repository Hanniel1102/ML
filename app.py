from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from PIL import Image
import io
import os
import json
import cv2
from datetime import datetime
import base64

# Thi·∫øt l·∫≠p TensorFlow tr∆∞·ªõc khi import
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # T·∫Øt warning

# Import TensorFlow
try:
    import tensorflow as tf
    # V·ªõi TensorFlow 2.15, s·ª≠ d·ª•ng tf.keras
    from tensorflow import keras
    print(f"‚úÖ TensorFlow version: {tf.__version__}")
except ImportError as e:
    print(f"‚ùå L·ªói import TensorFlow: {e}")
    raise

# Import module ti·ªÅn x·ª≠ l√Ω th√¥ng minh
from image_preprocessing import ImagePreprocessor, preprocess_and_check
# Import leaf detector
from leaf_detector import get_leaf_detector, analyze_leaf_image

app = FastAPI(title="Tomato Disease Detection API")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Bi·∫øn to√†n c·ª•c
model = None
class_names = None
IMG_SIZE = 256
preprocessor = ImagePreprocessor()

# File l∆∞u l·ªãch s·ª≠
HISTORY_FILE = "prediction_history.json"

# Load l·ªãch s·ª≠ t·ª´ file
def load_history():
    """Load l·ªãch s·ª≠ d·ª± ƒëo√°n t·ª´ file"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

# L∆∞u l·ªãch s·ª≠ v√†o file
def save_history(history):
    """L∆∞u l·ªãch s·ª≠ d·ª± ƒëo√°n v√†o file"""
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói l∆∞u l·ªãch s·ª≠: {e}")

# Th√™m k·∫øt qu·∫£ v√†o l·ªãch s·ª≠
def add_to_history(result_data):
    """Th√™m k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o l·ªãch s·ª≠"""
    history = load_history()
    
    # Gi·ªõi h·∫°n 100 k·∫øt qu·∫£ g·∫ßn nh·∫•t
    if len(history) >= 100:
        history = history[-99:]
    
    history.append(result_data)
    save_history(history)
    return len(history)

# Load model khi kh·ªüi ƒë·ªông
@app.on_event("startup")
async def load_model_startup():
    global model, class_names, IMG_SIZE
    
    print("üöÄ ƒêang kh·ªüi ƒë·ªông server...")
    
    # T√¨m v√† load model (∆∞u ti√™n model t·ªëi ∆∞u m·ªõi)
    model_paths = [
        "best_tomato_model.keras",  # Model t·ªëi ∆∞u m·ªõi nh·∫•t
        "Tomato_EfficientNetB0_Optimized.keras",  # Model t·ªëi ∆∞u backup
        "Tomato_EfficientNetB0_Final.keras",  # Model c≈©
        "test_model.keras",  # Model test
        "models/final_model.keras",
        "models/best_model.keras"
    ]
    
    # Define custom layers cho model t·ªëi ∆∞u
    @tf.keras.utils.register_keras_serializable()
    class SpatialAttention(tf.keras.layers.Layer):
        """Spatial Attention mechanism"""
        def __init__(self, kernel_size=7, **kwargs):
            super().__init__(**kwargs)
            self.kernel_size = kernel_size
            
        def build(self, input_shape):
            self.conv = tf.keras.layers.Conv2D(
                filters=1,
                kernel_size=self.kernel_size,
                padding='same',
                activation='sigmoid',
                use_bias=False
            )
            super().build(input_shape)
            
        def call(self, inputs):
            avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
            max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
            concat = tf.concat([avg_pool, max_pool], axis=-1)
            attention = self.conv(concat)
            return inputs * attention
        
        def get_config(self):
            config = super().get_config()
            config.update({"kernel_size": self.kernel_size})
            return config
    
    @tf.keras.utils.register_keras_serializable()
    class MixUp(tf.keras.layers.Layer):
        """MixUp augmentation layer"""
        def __init__(self, alpha=0.2, **kwargs):
            super().__init__(**kwargs)
            self.alpha = alpha
        
        def get_config(self):
            config = super().get_config()
            config.update({"alpha": self.alpha})
            return config
    
    custom_objects = {
        'SpatialAttention': SpatialAttention,
        'MixUp': MixUp
    }
    
    loaded_model = None
    for model_path in model_paths:
        if os.path.exists(model_path):
            try:
                print(f"üîÑ ƒêang load model t·ª´: {model_path}")
                # Th·ª≠ load v·ªõi custom objects cho model t·ªëi ∆∞u
                try:
                    loaded_model = keras.models.load_model(model_path, compile=False, custom_objects=custom_objects)
                except:
                    # Fallback: d√πng tf.keras
                    loaded_model = tf.keras.models.load_model(model_path, compile=False, custom_objects=custom_objects)
                
                model = loaded_model
                print(f"‚úÖ ƒê√£ load model: {model_path}")
                print(f"üìä Model info: input_shape={model.input_shape}, output_shape={model.output_shape}")
                
                # Compile l·∫°i model
                model.compile(
                    optimizer='adam',
                    loss='categorical_crossentropy',
                    metrics=['accuracy']
                )
                print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c compile l·∫°i")
                break
            except Exception as e:
                import traceback
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load model {model_path}:")
                print(f"   {str(e)[:300]}")
                traceback.print_exc()
                continue
    
    if model is None:
        print("‚ùå Kh√¥ng t√¨m th·∫•y model n√†o c√≥ th·ªÉ load ƒë∆∞·ª£c!")
        print("üí° Vui l√≤ng ki·ªÉm tra l·∫°i file model ho·∫∑c train l·∫°i model v·ªõi TensorFlow 2.15.0")
        raise RuntimeError("Model not found!")
    
    # Load class names
    if os.path.exists('models/class_names.json'):
        with open('models/class_names.json', 'r', encoding='utf-8') as f:
            class_names = json.load(f)
        print(f"‚úÖ ƒê√£ load class names t·ª´ file")
    else:
        # L·∫•y t·ª´ dataset n·∫øu t·ªìn t·∫°i
        test_dirs = [
            "Tomato/Test",
            "../Hocmaynangcao/Tomato/Test",
            "H:/nam4ki1/Hocmaynangcao/Tomato/Test"
        ]
        
        class_names = None
        # Kh√¥ng c·∫ßn load t·ª´ dataset, s·∫Ω d√πng fallback b√™n d∆∞·ªõi
        
        if class_names is None:
            # Fallback: s·ª≠ d·ª•ng keras.utils
            for test_dir in test_dirs:
                if os.path.exists(test_dir):
                    try:
                        temp_ds = keras.utils.image_dataset_from_directory(
                            test_dir,
                            image_size=(256, 256),
                            batch_size=32,
                            label_mode='categorical',
                            shuffle=False
                        )
                        class_names = temp_ds.class_names
                        print(f"‚úÖ ƒê√£ load class names t·ª´ keras.utils: {test_dir}")
                        break
                    except Exception as e:
                        # N·∫øu kh√¥ng ƒë∆∞·ª£c, ƒë·ªçc tr·ª±c ti·∫øp t·ª´ th∆∞ m·ª•c
                        try:
                            class_names = sorted([d for d in os.listdir(test_dir) 
                                                if os.path.isdir(os.path.join(test_dir, d))])
                            print(f"‚úÖ ƒê√£ load class names t·ª´ th∆∞ m·ª•c: {test_dir}")
                            break
                        except:
                            continue
        
        if class_names is None:
            # Fallback cu·ªëi c√πng: class names m·∫∑c ƒë·ªãnh
            class_names = [
                "Bacterial Spot",
                "Early Blight", 
                "Healthy",
                "Late Blight",
                "Septoria Leaf Spot",
                "Yellow Leaf Curl Virus"
            ]
            print(f"‚ö†Ô∏è S·ª≠ d·ª•ng class names m·∫∑c ƒë·ªãnh")
    
    IMG_SIZE = model.input_shape[1]
    print(f"üìè Image size: {IMG_SIZE}x{IMG_SIZE}")
    print(f"üìù S·ªë l∆∞·ª£ng classes: {len(class_names)}")
    print(f"‚úÖ Server ƒë√£ s·∫µn s√†ng!\n")

# API endpoint ch√≠nh
@app.get("/", response_class=HTMLResponse)
async def read_root():
    with open("templates/index.html", "r", encoding="utf-8") as f:
        return f.read()

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """API d·ª± ƒëo√°n b·ªánh t·ª´ ·∫£nh upload - v·ªõi ki·ªÉm tra th√¥ng minh"""
    global model, class_names, IMG_SIZE
    
    if model is None:
        raise HTTPException(status_code=503, detail="Model ch∆∞a ƒë∆∞·ª£c load")
    
    try:
        # ƒê·ªçc ·∫£nh
        contents = await file.read()
        img = Image.open(io.BytesIO(contents))
        
        # Chuy·ªÉn sang RGB n·∫øu c·∫ßn
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # === B∆Ø·ªöC 0: KI·ªÇM TRA NHANH - C√ì PH·∫¢I ·∫¢NH L√Å KH√îNG ===
        img_array_check = np.array(img)
        leaf_analysis = analyze_leaf_image(img_array_check)
        
        if not leaf_analysis['is_leaf']:
            return JSONResponse({
                "success": False,
                "error": "NOT_LEAF_IMAGE",
                "message": "‚ö†Ô∏è ·∫¢nh kh√¥ng ph·∫£i l√† ·∫£nh l√° c√¢y",
                "confidence": round(leaf_analysis['confidence'] * 100, 1),
                "reason": leaf_analysis['reason'],
                "recommendation": "Vui l√≤ng upload ·∫£nh l√° c√† chua ƒë·ªÉ ph√°t hi·ªán b·ªánh",
                "analysis": {
                    "green_score": round(leaf_analysis['details']['green_score'] * 100, 1),
                    "texture_score": round(leaf_analysis['details']['texture_score'] * 100, 1),
                    "shape_score": round(leaf_analysis['details']['shape_score'] * 100, 1),
                    "brightness_score": round(leaf_analysis['details']['brightness_score'] * 100, 1)
                }
            })
        
        # === B∆Ø·ªöC 1: KI·ªÇM TRA TH√îNG MINH ===
        # S·ª≠ d·ª•ng thu·∫≠t to√°n ƒëa t·∫ßng: texture + shape + color
        result = preprocess_and_check(img, target_size=(IMG_SIZE, IMG_SIZE))
        
        # N·∫øu KH√îNG ph·∫£i l√° c√¢y (ch√≥, m√®o, ng∆∞·ªùi, ƒë·ªì v·∫≠t)
        if not result['is_leaf']:
            details = result['details']
            # details c√≥ th·ªÉ l√† string (l√Ω do t·ª´ ch·ªëi) ho·∫∑c dict (ph√¢n t√≠ch chi ti·∫øt)
            if isinstance(details, str):
                # Tr∆∞·ªùng h·ª£p t·ª´ ch·ªëi s·ªõm v·ªõi l√Ω do string
                return JSONResponse({
                    "success": False,
                    "error": "NOT_LEAF_IMAGE",
                    "message": "·∫¢nh kh√¥ng ph·∫£i l√† ·∫£nh l√° c√¢y",
                    "reason": details,
                    "recommendation": "Vui l√≤ng ch·ªçn ·∫£nh l√° c√¢y th·∫≠t"
                })
            else:
                # Tr∆∞·ªùng h·ª£p c√≥ ph√¢n t√≠ch chi ti·∫øt
                return JSONResponse({
                    "success": False,
                    "error": "NOT_LEAF_IMAGE",
                    "message": "·∫¢nh kh√¥ng ph·∫£i l√† ·∫£nh l√° c√¢y",
                    "recommendation": details.get('recommendation', 'Vui l√≤ng ch·ªçn ·∫£nh l√° c√¢y'),
                    "analysis": {
                        "green_ratio": round(details.get('green_ratio', 0) * 100, 2),
                        "shadow_ratio": round(details.get('shadow_ratio', 0) * 100, 2),
                        "texture_score": round(details.get('texture_score', 0), 2),
                        "leaf_shape_score": round(details.get('leaf_shape_score', 0), 2),
                        "is_damaged_leaf": details.get('is_damaged_leaf', False),
                        "has_shadow": details.get('has_shadow', False)
                    }
                })

        # --- Additional safeguard ---
        # Ki·ªÉm tra ph·ª• ƒë·ªÉ gi·∫£m false-positives, nh∆∞ng ∆∞u ti√™n vein_score h∆°n
        details = result.get('details', {})
        
        # L·∫•y c√°c ch·ªâ s·ªë quan tr·ªçng
        vein_score = float(details.get('vein_score', details.get('texture_score', 0)))
        main_obj_ratio = float(details.get('main_object_ratio', 0))
        green_ratio = float(details.get('green_ratio', 0))
        leaf_shape_score = float(details.get('leaf_shape_score', 0))
        
        # Configurable thresholds via env vars
        MIN_VEIN_SCORE = float(os.environ.get('MIN_VEIN_SCORE', '0.20'))
        MIN_GREEN_RATIO = float(os.environ.get('MIN_GREEN_RATIO', '0.01'))
        
        # CHI·∫æN L∆Ø·ª¢C M·ªöI: Ch·∫∑n ch·ªâ khi C·∫¢ HAI ƒëi·ªÅu ki·ªán sau ƒë·ªÅu TH·∫§T B·∫†I:
        # 1. Kh√¥ng c√≥ g√¢n l√° r√µ (vein_score < 0.20)
        # 2. Kh√¥ng c√≥ m√†u xanh ho·∫∑c vegetation (green_ratio < 1%)
        # => ƒêi·ªÅu n√†y tr√°nh ch·∫∑n l√° th·∫≠t c√≥ g√¢n r√µ ho·∫∑c c√≥ m√†u xanh
        
        has_vein_structure = vein_score >= MIN_VEIN_SCORE
        has_vegetation = green_ratio >= MIN_GREEN_RATIO
        has_reasonable_shape = leaf_shape_score >= 0.15
        
        # Ch·ªâ t·ª´ ch·ªëi n·∫øu KH√îNG c√≥ g√¨ gi·ªëng l√° c·∫£
        is_likely_not_leaf = (not has_vein_structure and 
                              not has_vegetation and 
                              not has_reasonable_shape)
        
        # Allow override
        FORCE_PREDICT = os.environ.get('FORCE_PREDICT_ON_WEAK_LEAF', '0') == '1'
        
        if not FORCE_PREDICT and is_likely_not_leaf:
            # Return structured rejection with analysis
            return JSONResponse({
                "success": False,
                "error": "LOW_LEAF_CONFIDENCE",
                "message": "·∫¢nh c√≥ v·∫ª kh√¥ng ph·∫£i l√° c√¢y (kh√¥ng c√≥ g√¢n l√°, kh√¥ng c√≥ m√†u xanh, kh√¥ng c√≥ h√¨nh d·∫°ng l√°)",
                "recommendation": "Vui l√≤ng ch·ª•p l·∫°i ·∫£nh l√° r√µ r√†ng h∆°n",
                "analysis": {
                    "vein_score": round(vein_score, 3),
                    "green_ratio": round(green_ratio * 100, 2),
                    "leaf_shape_score": round(leaf_shape_score, 3),
                    "main_object_ratio": round(main_obj_ratio, 4),
                    "has_vein_structure": has_vein_structure,
                    "has_vegetation": has_vegetation,
                    "has_reasonable_shape": has_reasonable_shape
                }
            })
        
        # === B∆Ø·ªöC 2: S·ª¨ D·ª§NG ·∫¢NH ƒê√É TƒÇNG C∆Ø·ªúNG ===
        # ·∫¢nh ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông x·ª≠ l√Ω: tƒÉng s√°ng, l√†m n√©t, CLAHE
        enhanced_img = result['enhanced_image']
        img_array = np.array(enhanced_img)
        img_array = np.expand_dims(img_array, axis=0)
        
        # === B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN B·ªÜNH ===
        predictions = model.predict(img_array, verbose=0)
        predicted_class_idx = int(np.argmax(predictions[0]))
        confidence = float(predictions[0][predicted_class_idx] * 100)
        
        # Top 5 predictions
        num_top = min(5, len(class_names))
        top_idx = np.argsort(predictions[0])[-num_top:][::-1]
        top_predictions = [
            {
                "class": class_names[int(idx)],
                "confidence": float(predictions[0][idx] * 100)
            }
            for idx in top_idx
        ]
        
        # === B∆Ø·ªöC 4: PH√ÇN T√çCH CH·∫§T L∆Ø·ª¢NG ·∫¢NH ===
        details = result['details']
        image_analysis = {
            "type": "diseased_leaf" if details.get('is_diseased_leaf') else (
                    "shadow_leaf" if details.get('has_shadow') else (
                    "damaged_leaf" if details.get('is_damaged_leaf') else "healthy_leaf")),
            "green_ratio": round(details.get('green_ratio', 0) * 100, 2),
            "shadow_ratio": round(details.get('shadow_ratio', 0) * 100, 2),
            "texture_score": round(details.get('texture_score', 0), 2),
            "leaf_shape_score": round(details.get('leaf_shape_score', 0), 2),
            "brightness": round(details.get('brightness', 0), 1),
            "sharpness": round(details.get('sharpness', 0), 1),
            "recommendation": details.get('recommendation', '·∫¢nh ƒë·∫°t ch·∫•t l∆∞·ª£ng t·ªët')
        }
        
        # === B∆Ø·ªöC 5: L∆ØU V√ÄO L·ªäCH S·ª¨ ===
        # Convert ·∫£nh sang base64 ƒë·ªÉ l∆∞u thumbnail
        img_thumbnail = img.copy()
        img_thumbnail.thumbnail((150, 150))
        buffered = io.BytesIO()
        img_thumbnail.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        history_entry = {
            "id": len(load_history()) + 1,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "filename": file.filename,
            "predicted_class": class_names[predicted_class_idx],
            "confidence": round(confidence, 2),
            "image_type": image_analysis["type"],
            "vein_score": round(details.get('vein_score', 0), 2),
            "thumbnail": f"data:image/jpeg;base64,{img_base64}"
        }
        add_to_history(history_entry)
        
        response_data = {
            "success": True,
            "predicted_class": class_names[predicted_class_idx],
            "confidence": confidence,
            "top_predictions": top_predictions,
            "image_analysis": image_analysis,
            "preprocessing": "enhanced" if details.get('is_dark_detected') else "standard",
            "history_id": history_entry["id"]
        }
        
        return JSONResponse(response_data)
        
    except Exception as e:
        import traceback
        traceback.print_exc()  # In ra console ƒë·ªÉ debug
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}")

@app.get("/history")
async def get_history():
    """L·∫•y l·ªãch s·ª≠ d·ª± ƒëo√°n"""
    try:
        history = load_history()
        # S·∫Øp x·∫øp theo th·ªùi gian m·ªõi nh·∫•t
        history.reverse()
        return JSONResponse({
            "success": True,
            "count": len(history),
            "history": history
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.delete("/history/{item_id}")
async def delete_history_item(item_id: int):
    """X√≥a m·ªôt item trong l·ªãch s·ª≠"""
    try:
        history = load_history()
        history = [h for h in history if h.get('id') != item_id]
        save_history(history)
        return JSONResponse({
            "success": True,
            "message": "ƒê√£ x√≥a th√†nh c√¥ng"
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.delete("/history")
async def clear_history():
    """X√≥a to√†n b·ªô l·ªãch s·ª≠"""
    try:
        save_history([])
        return JSONResponse({
            "success": True,
            "message": "ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠"
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.get("/health")
async def health_check():
    """Ki·ªÉm tra tr·∫°ng th√°i server"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "num_classes": len(class_names) if class_names else 0
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
