"""
Data Preprocessing Pipeline - Ph·ª•c h·ªìi ·∫£nh x·∫•u trong dataset
S·ª≠a ch·ªØa c√°c ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng k√©m (noise, blur, dark, low contrast) 
ƒë·ªÉ tr·∫£ v·ªÅ dataset s·∫°ch, ch·∫•t l∆∞·ª£ng t·ªët cho training
"""

import os
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
from tqdm import tqdm
import shutil


class DatasetPreprocessor:
    """
    PH·ª§C H·ªíI ·∫£nh x·∫•u trong dataset v·ªÅ ch·∫•t l∆∞·ª£ng t·ªët
    
    Ch·ª©c nƒÉng:
    - T·ª± ƒë·ªông ph√°t hi·ªán ·∫£nh x·∫•u (t·ªëi, m·ªù, nhi·ªÖu, low contrast)
    - √Åp d·ª•ng enhancement m·∫°nh m·∫Ω ƒë·ªÉ s·ª≠a ch·ªØa
    - Tr·∫£ v·ªÅ dataset s·∫°ch, ƒë·ªìng nh·∫•t ƒë·ªÉ train model
    
    Kh√°c v·ªõi efficientnet_preprocessor.py (ch·ªâ √°p d·ª•ng khi c·∫ßn),
    file n√†y √ÅP D·ª§NG CHO T·∫§T C·∫¢ ·∫¢NH ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng ƒë·ªìng nh·∫•t.
    """
    
    def __init__(self, target_size=(256, 256), aggressive_fix=True):
        """
        Args:
            target_size: K√≠ch th∆∞·ªõc ƒë·∫ßu ra (width, height)
            aggressive_fix: S·ª≠a m·∫°nh tay (True) hay ch·ªâ s·ª≠a khi c·∫ßn (False)
        """
        self.target_size = target_size
        self.aggressive_fix = aggressive_fix
        
        # Ng∆∞·ª°ng ph√°t hi·ªán ·∫£nh x·∫•u (th·∫•p h∆°n = s·ª≠a nhi·ªÅu h∆°n)
        self.brightness_low = 100    # < 100 = t·ªëi
        self.brightness_high = 180   # > 180 = s√°ng
        self.contrast_low = 35       # < 35 = low contrast
        self.noise_high = 500        # < 500 = nhi·ªÖu cao
        self.sharpness_low = 40      # < 40 = m·ªù
        
    def fix_bad_image(self, image_path):
        """
        PH·ª§C H·ªíI ·∫£nh x·∫•u v·ªÅ ch·∫•t l∆∞·ª£ng t·ªët:
        1. Load ·∫£nh
        2. Ph√¢n t√≠ch v·∫•n ƒë·ªÅ (t·ªëi/m·ªù/nhi·ªÖu/low contrast)
        3. √Åp d·ª•ng s·ª≠a ch·ªØa M·∫†NH T·∫§Y:
           - Denoise TR∆Ø·ªöC (gi·∫£m nhi·ªÖu)
           - Brightness adjustment (s·ª≠a t·ªëi/s√°ng)
           - CLAHE (tƒÉng contrast)
           - Sharpen (l√†m n√©t)
        4. Resize v·ªÅ target_size
        5. Tr·∫£ v·ªÅ ·∫£nh ƒë√£ ph·ª•c h·ªìi
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh x·∫•u
            
        Returns:
            numpy array: ·∫¢nh ƒë√£ ph·ª•c h·ªìi (ch·∫•t l∆∞·ª£ng t·ªët)
        """
        try:
            # 1. Load ·∫£nh
            img = Image.open(image_path).convert('RGB')
            img_array = np.array(img)
            
            # 2. Ph√¢n t√≠ch v·∫•n ƒë·ªÅ
            metrics = self._analyze_image(img_array)
            issues = self._detect_issues(metrics)
            
            # 3. S·ª≠a ch·ªØa theo th·ª© t·ª± t·ªëi ∆∞u
            fixed_img = img_array.copy()
            
            # B∆∞·ªõc 1: DENOISE TR∆Ø·ªöC (quan tr·ªçng!)
            # Ph·∫£i kh·ª≠ nhi·ªÖu tr∆∞·ªõc khi l√†m c√°c thao t√°c kh√°c
            if issues['has_noise'] or self.aggressive_fix:
                fixed_img = self._fix_noise(fixed_img, metrics)
            
            # B∆∞·ªõc 2: Fix brightness (s·ª≠a t·ªëi/s√°ng)
            if issues['too_dark'] or issues['too_bright'] or self.aggressive_fix:
                fixed_img = self._fix_brightness(fixed_img, metrics)
            
            # B∆∞·ªõc 3: Fix contrast (CLAHE)
            if issues['low_contrast'] or self.aggressive_fix:
                fixed_img = self._fix_contrast(fixed_img, metrics)
            
            # B∆∞·ªõc 4: Sharpen (l√†m n√©t)
            if issues['blurry'] or self.aggressive_fix:
                fixed_img = self._fix_sharpness(fixed_img, metrics)
            
            # 5. Resize v·ªÅ target size (b∆∞·ªõc cu·ªëi)
            fixed_img = self._resize_image(fixed_img)
            
            return fixed_img
            
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {image_path}: {e}")
            return None
    
    def _detect_issues(self, metrics):
        """
        Ph√°t hi·ªán v·∫•n ƒë·ªÅ c·ªßa ·∫£nh
        
        Returns:
            dict: {
                'too_dark': bool,
                'too_bright': bool,
                'low_contrast': bool,
                'has_noise': bool,
                'blurry': bool
            }
        """
        return {
            'too_dark': metrics['brightness'] < self.brightness_low,
            'too_bright': metrics['brightness'] > self.brightness_high,
            'low_contrast': metrics['contrast'] < self.contrast_low,
            'has_noise': metrics['noise_variance'] < self.noise_high,
            'blurry': metrics['edge_strength'] < self.sharpness_low
        }
    
    def _resize_image(self, img_array):
        """Resize ·∫£nh v·ªÅ target_size"""
        h, w = img_array.shape[:2]
        target_w, target_h = self.target_size
        
        # Ch·ªçn interpolation method ph√π h·ª£p
        if h > target_h or w > target_w:
            interpolation = cv2.INTER_AREA  # Shrink - ch·∫•t l∆∞·ª£ng t·ªët
        else:
            interpolation = cv2.INTER_CUBIC  # Upscale - smooth h∆°n
        
        resized = cv2.resize(img_array, (target_w, target_h), interpolation=interpolation)
        return resized
    
    def _analyze_image(self, img_array):
        """
        Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng ·∫£nh
        Returns:
            dict: brightness, contrast, noise_variance, edge_strength
        """
        # Convert to grayscale
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # 1. Brightness
        brightness = np.mean(gray)
        
        # 2. Contrast (std deviation)
        contrast = np.std(gray)
        
        # 3. Noise (Laplacian variance)
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        noise_variance = laplacian.var()
        
        # 4. Sharpness (Sobel gradient magnitude)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        edge_strength = np.mean(np.sqrt(sobelx**2 + sobely**2))
        
        return {
            'brightness': brightness,
            'contrast': contrast,
            'noise_variance': noise_variance,
            'edge_strength': edge_strength
        }
    
    def _fix_noise(self, img_array, metrics):
        """
        Kh·ª≠ nhi·ªÖu M·∫†NH ƒë·ªÉ ph·ª•c h·ªìi ·∫£nh nhi·ªÖu
        """
        noise_var = metrics['noise_variance']
        
        if noise_var < 200:
            # Nhi·ªÖu R·∫§T n·∫∑ng - bilateral filter c·ª±c m·∫°nh
            denoised = cv2.bilateralFilter(img_array, 9, 75, 75)
            print("      ‚Üí Kh·ª≠ nhi·ªÖu R·∫§T M·∫†NH (bilateral d=9)")
        elif noise_var < 400:
            # Nhi·ªÖu n·∫∑ng - bilateral filter m·∫°nh
            denoised = cv2.bilateralFilter(img_array, 7, 60, 60)
            print("      ‚Üí Kh·ª≠ nhi·ªÖu M·∫†NH (bilateral d=7)")
        else:
            # Nhi·ªÖu nh·∫π - bilateral filter v·ª´a
            denoised = cv2.bilateralFilter(img_array, 5, 40, 40)
            print("      ‚Üí Kh·ª≠ nhi·ªÖu (bilateral d=5)")
        
        return denoised
    
    def _fix_brightness(self, img_array, metrics):
        """
        S·ª≠a ƒë·ªô s√°ng v·ªÅ m·ª©c chu·∫©n (120-150)
        """
        brightness = metrics['brightness']
        target_brightness = 135  # Target brightness chu·∫©n
        
        # Convert to LAB
        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        
        if brightness < self.brightness_low:
            # ·∫¢nh T·ªêI - tƒÉng s√°ng m·∫°nh
            alpha = target_brightness / brightness if brightness > 0 else 1.8
            alpha = min(alpha, 2.5)  # Gi·ªõi h·∫°n t·ªëi ƒëa
            beta = 30
            l = np.clip(l * alpha + beta, 0, 255).astype(np.uint8)
            print(f"      ‚Üí TƒÉng s√°ng: {brightness:.0f} ‚Üí {target_brightness}")
            
        elif brightness > self.brightness_high:
            # ·∫¢nh S√ÅNG - gi·∫£m s√°ng
            alpha = target_brightness / brightness
            beta = -15
            l = np.clip(l * alpha + beta, 0, 255).astype(np.uint8)
            print(f"      ‚Üí Gi·∫£m s√°ng: {brightness:.0f} ‚Üí {target_brightness}")
        
        # Merge back
        lab = cv2.merge([l, a, b])
        fixed = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        return fixed
    
    def _fix_contrast(self, img_array, metrics):
        """
        TƒÉng contrast b·∫±ng CLAHE M·∫†NH
        """
        contrast = metrics['contrast']
        
        # Convert to LAB
        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        
        if contrast < 25:
            # Contrast R·∫§T th·∫•p - CLAHE r·∫•t m·∫°nh
            clahe = cv2.createCLAHE(clipLimit=3.5, tileGridSize=(8, 8))
            print("      ‚Üí TƒÉng contrast R·∫§T M·∫†NH (CLAHE 3.5)")
        elif contrast < self.contrast_low:
            # Contrast th·∫•p - CLAHE m·∫°nh
            clahe = cv2.createCLAHE(clipLimit=2.8, tileGridSize=(8, 8))
            print("      ‚Üí TƒÉng contrast M·∫†NH (CLAHE 2.8)")
        else:
            # Contrast v·ª´a - CLAHE nh·∫π
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            print("      ‚Üí TƒÉng contrast (CLAHE 2.0)")
        
        l = clahe.apply(l)
        
        # Merge back
        lab = cv2.merge([l, a, b])
        fixed = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        return fixed
    
    def _fix_sharpness(self, img_array, metrics):
        """
        L√†m n√©t ·∫£nh m·ªù b·∫±ng unsharp masking M·∫†NH
        """
        edge_strength = metrics['edge_strength']
        
        if edge_strength < 25:
            # ·∫¢nh R·∫§T m·ªù - sharpen c·ª±c m·∫°nh
            kernel = np.array([[-1, -1, -1],
                             [-1, 10, -1],
                             [-1, -1, -1]])
            print("      ‚Üí L√†m n√©t R·∫§T M·∫†NH (kernel 10)")
        elif edge_strength < self.sharpness_low:
            # ·∫¢nh m·ªù - sharpen m·∫°nh
            kernel = np.array([[-1, -1, -1],
                             [-1,  9, -1],
                             [-1, -1, -1]])
            print("      ‚Üí L√†m n√©t M·∫†NH (kernel 9)")
        else:
            # ·∫¢nh h∆°i m·ªù - sharpen v·ª´a
            kernel = np.array([[0, -1, 0],
                             [-1,  6, -1],
                             [0, -1, 0]])
            print("      ‚Üí L√†m n√©t (kernel 6)")
        
        sharpened = cv2.filter2D(img_array, -1, kernel)
        return sharpened
    
    def process_dataset(self, input_dir, output_dir, mode='fix'):
        """
        PH·ª§C H·ªíI to√†n b·ªô dataset x·∫•u v·ªÅ ch·∫•t l∆∞·ª£ng t·ªët
        
        Args:
            input_dir: Th∆∞ m·ª•c dataset X·∫§U (Train_Bad/Test_Bad/Val_Bad)
            output_dir: Th∆∞ m·ª•c l∆∞u dataset ƒê√É S·ª¨A (Train_Fixed/Test_Fixed/Val_Fixed)
            mode: 'fix' (s·ª≠a ·∫£nh x·∫•u) ho·∫∑c 'resize' (ch·ªâ resize)
            
        Returns:
            dict: Th·ªëng k√™ x·ª≠ l√Ω
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        
        if not input_path.exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {input_path}")
            return None
        
        print(f"\n{'='*70}")
        print(f"üîß B·∫ÆT ƒê·∫¶U PH·ª§C H·ªíI DATASET X·∫§U")
        print(f"{'='*70}")
        print(f"üìÅ Input (·∫£nh X·∫§U): {input_path}")
        print(f"üíæ Output (·∫£nh ƒê√É S·ª¨A): {output_path}")
        print(f"üéØ Target size: {self.target_size}")
        print(f"‚ö° Mode: {'FIX (s·ª≠a m·∫°nh)' if mode == 'fix' else 'RESIZE (ch·ªâ resize)'}")
        print(f"üí™ Aggressive fix: {'ON' if self.aggressive_fix else 'OFF'}")
        print(f"{'='*70}\n")
        
        stats = {
            'total_processed': 0,
            'total_failed': 0,
            'classes': {}
        }
        
        # T√¨m t·∫•t c·∫£ c√°c class folders
        class_folders = [d for d in input_path.iterdir() if d.is_dir()]
        
        for class_folder in class_folders:
            class_name = class_folder.name
            output_class_dir = output_path / class_name
            output_class_dir.mkdir(parents=True, exist_ok=True)
            
            # T√¨m t·∫•t c·∫£ ·∫£nh trong class
            image_files = list(class_folder.glob("*.jpg")) + \
                         list(class_folder.glob("*.jpeg")) + \
                         list(class_folder.glob("*.png"))
            
            if len(image_files) == 0:
                print(f"‚ö†Ô∏è  {class_name}: Kh√¥ng c√≥ ·∫£nh")
                continue
            
            print(f"üìÇ ƒêang ph·ª•c h·ªìi {class_name}: {len(image_files)} ·∫£nh x·∫•u...")
            
            processed_count = 0
            failed_count = 0
            fixed_count = 0
            
            # X·ª≠ l√Ω t·ª´ng ·∫£nh v·ªõi progress bar
            for img_path in tqdm(image_files, desc=f"   {class_name[:28]:28s}", ncols=80):
                try:
                    if mode == 'fix':
                        # PH·ª§C H·ªíI ·∫£nh x·∫•u
                        fixed_img = self.fix_bad_image(img_path)
                        fixed_count += 1
                    else:
                        # Ch·ªâ resize
                        img = Image.open(img_path).convert('RGB')
                        img_array = np.array(img)
                        fixed_img = self._resize_image(img_array)
                    
                    if fixed_img is not None:
                        # L∆∞u ·∫£nh ƒë√£ s·ª≠a
                        output_img_path = output_class_dir / img_path.name
                        img_pil = Image.fromarray(fixed_img.astype(np.uint8))
                        img_pil.save(output_img_path, quality=95, optimize=True)
                        
                        processed_count += 1
                        stats['total_processed'] += 1
                    else:
                        failed_count += 1
                        stats['total_failed'] += 1
                        
                except Exception as e:
                    print(f"\n   ‚ùå L·ªói: {img_path.name} - {e}")
                    failed_count += 1
                    stats['total_failed'] += 1
            
            stats['classes'][class_name] = {
                'total': len(image_files),
                'fixed': fixed_count if mode == 'fix' else 0,
                'processed': processed_count,
                'failed': failed_count
            }
            
            print(f"   ‚úÖ ƒê√£ s·ª≠a: {processed_count}, ‚ùå L·ªói: {failed_count}\n")
        
        # T·ªïng k·∫øt
        print(f"{'='*70}")
        print(f"üéâ HO√ÄN T·∫§T PH·ª§C H·ªíI DATASET")
        print(f"{'='*70}")
        print(f"üìä T·ªïng k·∫øt:")
        print(f"   ‚úÖ ·∫¢nh ƒë√£ ph·ª•c h·ªìi th√†nh c√¥ng: {stats['total_processed']}")
        print(f"   ‚ùå ·∫¢nh l·ªói: {stats['total_failed']}")
        print(f"\nüìÅ Dataset s·∫°ch ƒë√£ l∆∞u t·∫°i: {output_path.absolute()}")
        print(f"üí° B√¢y gi·ªù c√≥ th·ªÉ train model v·ªõi dataset n√†y!")
        print(f"{'='*70}\n")
        
        return stats
    
    def process_all_splits(self, root_dir, output_root_dir, 
                          splits=['Train', 'Val', 'Test'], mode='fix'):
        """
        PH·ª§C H·ªíI t·∫•t c·∫£ splits (Train/Val/Test) t·ª´ dataset x·∫•u
        
        Args:
            root_dir: Th∆∞ m·ª•c g·ªëc ch·ª©a Train_Bad/Val_Bad/Test_Bad
            output_root_dir: Th∆∞ m·ª•c ƒë√≠ch (Train_Fixed/Val_Fixed/Test_Fixed)
            splits: List c√°c splits c·∫ßn x·ª≠ l√Ω
            mode: 'fix' (s·ª≠a ·∫£nh x·∫•u) ho·∫∑c 'resize' (ch·ªâ resize)
        """
        root_path = Path(root_dir)
        output_root_path = Path(output_root_dir)
        
        print(f"\n{'='*70}")
        print(f"üî• B·∫ÆT ƒê·∫¶U PH·ª§C H·ªíI TO√ÄN B·ªò DATASET X·∫§U")
        print(f"{'='*70}")
        print(f"üìÅ Input: Dataset X·∫§U t·ª´ {root_path}")
        print(f"üíæ Output: Dataset S·∫†CH v√†o {output_root_path}")
        print(f"{'='*70}\n")
        
        all_stats = {}
        
        for split in splits:
            split_dir = root_path / split
            if not split_dir.exists():
                print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y split: {split}")
                continue
            
            output_split_dir = output_root_path / split
            stats = self.process_dataset(split_dir, output_split_dir, mode=mode)
            
            if stats:
                all_stats[split] = stats
        
        # T·ªïng k·∫øt to√†n b·ªô
        print(f"\n{'='*70}")
        print(f"üèÜ T·ªîNG K·∫æT PH·ª§C H·ªíI TO√ÄN B·ªò DATASET")
        print(f"{'='*70}")
        
        total_all = sum(stats['total_processed'] for stats in all_stats.values())
        failed_all = sum(stats['total_failed'] for stats in all_stats.values())
        
        for split, stats in all_stats.items():
            print(f"\nüì¶ {split}:")
            print(f"   ‚úÖ ƒê√£ s·ª≠a th√†nh c√¥ng: {stats['total_processed']}")
            print(f"   ‚ùå L·ªói: {stats['total_failed']}")
            print(f"   üìã Classes:")
            for class_name, class_stats in stats['classes'].items():
                print(f"      - {class_name:30s}: {class_stats['processed']:4d} ·∫£nh")
        
        print(f"\n{'='*70}")
        print(f"üéØ T·ªîNG C·ªòNG:")
        print(f"   ‚úÖ {total_all} ·∫£nh ƒë√£ ph·ª•c h·ªìi th√†nh c√¥ng")
        print(f"   ‚ùå {failed_all} ·∫£nh l·ªói")
        print(f"\nüí° Dataset s·∫°ch ƒë√£ s·∫µn s√†ng ƒë·ªÉ train model!")
        print(f"{'='*70}\n")
        
        return all_stats


# ==========================================
# MAIN - Ch·∫°y preprocessing
# ==========================================
if __name__ == "__main__":
    """
    PH·ª§C H·ªíI dataset x·∫•u v·ªÅ ch·∫•t l∆∞·ª£ng t·ªët ƒë·ªÉ train model
    
    Lu·ªìng s·ª≠ d·ª•ng:
    1. D√πng data_raw.py ƒë·ªÉ t·∫°o dataset x·∫•u (noise/blur/dark)
    2. D√πng file n√†y ƒë·ªÉ S·ª¨A dataset x·∫•u v·ªÅ ch·∫•t l∆∞·ª£ng t·ªët
    3. Train model v·ªõi dataset ƒë√£ s·ª≠a
    
    C√°ch ch·∫°y:
        python data_preprocessing.py
    """
    
    # ============ C·∫§U H√åNH ============
    INPUT_DIR = "Tomato/Augmented_Train"  # Dataset X·∫§U (t·ª´ data_raw.py)
    OUTPUT_DIR = "Tomato/Fixed_Train"     # Dataset ƒê√É S·ª¨A (s·∫°ch, ch·∫•t l∆∞·ª£ng t·ªët)
    TARGET_SIZE = (256, 256)              # K√≠ch th∆∞·ªõc ƒë·∫ßu ra
    AGGRESSIVE_FIX = True                 # S·ª≠a m·∫°nh tay (True) hay ch·ªâ s·ª≠a khi c·∫ßn (False)
    MODE = 'fix'                          # 'fix' (s·ª≠a ·∫£nh x·∫•u) ho·∫∑c 'resize' (ch·ªâ resize)
    
    # ============ KH·ªûI T·∫†O ============
    preprocessor = DatasetPreprocessor(
        target_size=TARGET_SIZE,
        aggressive_fix=AGGRESSIVE_FIX
    )
    
    # ============ CH·∫†Y PH·ª§C H·ªíI ============
    print("\nüîß X·ª¨ L√ù DATASET X·∫§U V·ªÄ CH·∫§T L∆Ø·ª¢NG T·ªêT")
    print(f"üìÇ Input: Dataset X·∫§U t·ª´ data_raw.py ({INPUT_DIR})")
    print(f"üíæ Output: Dataset S·∫†CH ƒë·ªÉ train ({OUTPUT_DIR})")
    print("="*70)
    
    stats = preprocessor.process_dataset(
        input_dir=INPUT_DIR,
        output_dir=OUTPUT_DIR,
        mode=MODE
    )
    
    if stats:
        print("\n‚úÖ X·ª≠ l√Ω dataset ho√†n t·∫•t!")
        print(f"üí° Dataset s·∫°ch ƒë√£ s·∫µn s√†ng t·∫°i: {OUTPUT_DIR}/")
        print(f"üí° Train model: train_datagen.flow_from_directory('{OUTPUT_DIR}')")
        print(f"\nüìä Th·ªëng k√™:")
        print(f"   - T·ªïng ·∫£nh ƒë√£ s·ª≠a: {stats['total_processed']}")
        print(f"   - T·ªïng ·∫£nh l·ªói: {stats['total_failed']}")
        
        # Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng class
        print(f"\nüìã Chi ti·∫øt t·ª´ng class:")
        for class_name, class_stats in stats['classes'].items():
            print(f"   {class_name:30s}: {class_stats['processed']}/{class_stats['total']} ·∫£nh")
    else:
        print("\n‚ùå Ph·ª•c h·ªìi th·∫•t b·∫°i!")
        exit(1)
